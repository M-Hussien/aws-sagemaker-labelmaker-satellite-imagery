{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mx_lenet_sagemaker.py\n",
    "import logging\n",
    "from os import path as op\n",
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/\"\n",
    "batch_size = 50\n",
    "num_cpus = 0\n",
    "num_gpus = 1\n",
    "\n",
    "def prep_data(data_path):\n",
    "    \"\"\"\n",
    "    Convert numpy array to mx Nd-array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: the directory that save data.npz.\n",
    "    \"\"\"\n",
    "    data = np.load(find_file(data_path, 'data.npz'))\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train'][:,:1] ## only take the second column of y_train\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test'][:,:1]\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    img_mean = np.mean(x_train, axis=(0, 1, 2))\n",
    "    img_std = np.std(x_train, axis=(0, 1, 2))\n",
    "    \n",
    "    x_train -= img_mean\n",
    "    x_train /= img_std\n",
    "    x_test -= img_mean\n",
    "    x_test /= img_std\n",
    "\n",
    "    img_rows = 256\n",
    "    img_cols = 256\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols) ## reshape it to (448, ) instead of (448,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    y_train = y_train.reshape(y_train.shape[0], )\n",
    "    y_test = y_test.reshape(y_test.shape[0], )\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    train_iter = mx.io.NDArrayIter(x_train, y_train, batch_size, shuffle=True)\n",
    "    val_iter = mx.io.NDArrayIter(x_test, y_test, batch_size)\n",
    "\n",
    "    return train_iter, val_iter\n",
    "\n",
    "def find_file(root_path, file_name):\n",
    "    \"\"\"\n",
    "    Searching for data.npz at its root director, and return a full path for the file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path: the root directory for data.npz.\n",
    "    file_name: refers to data.npz\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        if file_name in files:\n",
    "            return os.path.join(root, file_name)\n",
    "\n",
    "def mx_lenet():\n",
    "    \"\"\"Building a three layer LeNet sytle Convolutional Neural Net using MXNet.\"\"\"\n",
    "    data = mx.sym.var('data')\n",
    "    data_dp = mx.symbol.Dropout(data, p = 0.2) ## 20% of the input that gets dropped out during training time\n",
    "    # first conv layer\n",
    "    conv1 = mx.sym.Convolution(data=data_dp, kernel=(5, 5), num_filter=20)\n",
    "    tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # second conv layer\n",
    "    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\n",
    "    tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    \n",
    "    # third conv layer\n",
    "    conv3 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\n",
    "    tanh3 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool3 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    \n",
    "    # first fullc layer\n",
    "    flatten = mx.sym.flatten(data=pool3)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh4 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.sym.FullyConnected(data=tanh4, num_hidden=2)\n",
    "    # softmax loss\n",
    "    return mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "\n",
    "\n",
    "def train(num_cpus, num_gpus, **kwargs):\n",
    "    \"\"\"\n",
    "    Train the image classification neural net.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    train_iter, val_iter = prep_data(data_path)\n",
    "    lenet = mx_lenet()\n",
    "    lenet_model = mx.mod.Module(\n",
    "        symbol=lenet,\n",
    "        context=get_train_context(num_cpus, num_gpus))\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    lenet_model.fit(train_iter,\n",
    "                    eval_data=val_iter,\n",
    "                    optimizer='sgd',\n",
    "                    optimizer_params={'learning_rate': 0.1},\n",
    "                    eval_metric='acc',\n",
    "                    batch_end_callback=mx.callback.Speedometer(batch_size, 16),\n",
    "                    num_epoch=100)\n",
    "    return lenet_model\n",
    "\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    \"\"\"\n",
    "    Define the model training instance.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    if num_gpus > 0:\n",
    "        return mx.gpu()\n",
    "    return mx.cpu()\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    if num_gpus > 0:\n",
    "        print(\"It's {} instance\".format(num_gpus))\n",
    "        return mx.gpu()\n",
    "    print(\"It's {} instance\".format(num_cpus))\n",
    "    return mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "mxnet_estimator = MXNet(\"mx_lenet_sagemaker.py\", \n",
    "                        role=get_execution_role(), \n",
    "                        train_instance_type=\"ml.p2.xlarge\", \n",
    "                        train_instance_count=1)\n",
    "mxnet_estimator.fit(\"s3://data-754487812300\") ## give your s3 bucket URL here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = mxnet_estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "import botocore\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def pred_img(bucket, img_s3, img_nn, image_mean, image_std):\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    try:\n",
    "        s3.Bucket(bucket).download_file(img_s3, img_nn)\n",
    "        print(\"{} download under current directory\".format(img_s3))\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise\n",
    "    img=Image.open(img_nn)\n",
    "    img_np = np.array(img).astype('float32')\n",
    "    # RBG chanels are between 0-255, so rescale it to be between 0-1.\n",
    "    img_np /=255\n",
    "    img_np -= image_mean\n",
    "    img_np /= image_std\n",
    "    #reshape the image to (1, 3, 256, 256) to pass to the predictor of MXNet Estimator\n",
    "    img_np = img_np.reshape(1,img_np.shape[2],img_np.shape[0], img_np.shape[1]) \n",
    "    pred = predictor.predict(img_np)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your bucket name\n",
    "bucket = 'data-754487812300'\n",
    "# full path to the test image\n",
    "img_s3 = 'tiles/65935-63265-17.jpg' \n",
    "# the new given name for the image you wanna save in current work directory\n",
    "img_nn = \"Image_1.jpg\"\n",
    "\n",
    "\"\"\"\n",
    "Image mean and image_std are obtained from data.npz's by \n",
    "running img_mean = np.mean(x_train, axis=(0, 1, 2)), img_std = np.std(x_train, axis=(0, 1, 2))\n",
    "\"\"\"\n",
    "image_mean = np.array([ 0.14663778,  0.1624524 , -0.21313858]).astype('float32')\n",
    "image_std = np.array([ 0.86569798,  0.77569193,  0.79192579]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_img(bucket, img_s3, img_nn, image_mean, image_std)\n",
    "image_1 = plt.imread(\"Image_1.jpg\")\n",
    "plt.imshow(image_1)\n",
    "print(\"The overall prediction is: {}\".format(pred))\n",
    "for item in pred:\n",
    "    print(\"item[0]: \", item[0])\n",
    "    print(\"item[1]: \", item[1])\n",
    "    if item[0] > item[1]:\n",
    "        print(\"It's background tile\")\n",
    "    else:\n",
    "        print(\"The tile contains building(s)!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
